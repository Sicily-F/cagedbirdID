{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4. Getting set up with Python and GPU support for Tensorflow.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sicily-F/cagedbirdID/blob/main/4_Getting_set_up_with_Python_and_GPU_support_for_Tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bPHgvzAcx54y"
      },
      "source": [
        "# 4. Hardware requirements: setting up Python and downloading TensorFlow with GPU support\n",
        "\n",
        "\n",
        "Please note that this code is specifically geared for Windows users, though, where possible we will highlight how the same code can be run on Linux terminals, especially for command line tasks. The Python code itself is relatively agnostic depending on your operating system. \n",
        "\n",
        "## Hardware requirements\n",
        "The code given in this repository was tested on a machine equipped with the following\n",
        "* Operating System: Windows 10 Pro\n",
        "* GPU: NVIDIA GeForce MX150 (may be referred to on your computer as a graphics card)\n",
        "* Processor: Intel(R) Core(TM) i7-8550U CPU @ 1.80GHz, 1992 Mhz, 4 Core(s), 8 Logical Processor(s)\n",
        "* RAM: Installed physical memory (RAM) of 8 GB\n",
        "* Python version: 3.8 \n",
        "\n",
        "\n",
        "In their Github [repository](https://github.com/AndreCFerreira/Bird_individualID), Ferreira et al. (2020) highlight this useful hardware [guide](https://timdettmers.com/2018/12/16/deep-learning-hardware-guide/) for deep learning.\n",
        "For the HPC system, your code is run via PuTty (the world's most popular free SSH, also known as Secure Shell or Secure Socket Shell (SSH) client) which is a Linux-based system. The Dockerfile runs on Ubuntu 18.4 on this system- this is an NVIDIA base image, with Python and other deep learning and data manipulation packages included.\n",
        "\n",
        "You can check your hardware specifications on a Window System in two ways:\n",
        "* Settings > System > About\n",
        "* System Information > OS Name, Processor information and Installed Physical Memory (RAM) for your available RAM\n",
        "\n",
        "To check the name of your GPU, so you know what you’re looking for, you can also type in your search bar\n",
        "* Device Manager > Display Adaptors > the name of your processor and GPU will be displayed here\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGODpmfKyPpi"
      },
      "source": [
        "## Downloading and setting up Python\n",
        "* You can install the latest version of Python using [Anaconda](https://www.anaconda.com/products/individual); the main data science toolkit for using Python and other integrated development environments (IDE) such as Spyder (like a very retro version of RStudio, if that’s what you use)\n",
        "* Other ways you can run code include [PyCharm](https://hackr.io/blog/best-python-ide) and similar environments.\n",
        "* If you want to test, share or edit code with others, [Google Colaboratory](https://colab.research.google.com/notebooks/intro.ipynb?utm_source=scs-index) is excellent. You can run Python in your browser without having to run it locally or even download Python; all of the code presented here will run the same in Google Colab\n",
        "* It is recommended to run your code locally in virtual environments, which are mini-projects where package versions can be installed, and they are unique to this environment\n",
        "Ferreira et al. excellently describe [how](https://github.com/AndreCFerreira/Bird_individualID/tree/master/Requirements) to create a virtual environment. They use a Linux terminal, but if you are on a Windows machine then you can perform exactly the same steps in the Anaconda Prompt terminal, which you can find in your search bar after installing Anaconda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYzyAuIu0_uW"
      },
      "source": [
        "## Importing packages more generally (SW: this is installing rather than importing)\n",
        "There are two ways you can do this\n",
        "1. Using pip within Python itself or an IDE\n",
        "\n",
        "\n",
        "```\n",
        "pip install <name of the module>\n",
        "```\n",
        "\n",
        "I find pip a bit more reliable, but make sure you are doing this after activating your conda environment, so all your packages are installed in your new virtual environment rather than on your base environment.\n",
        "\n",
        "2. Via the Anaconda command line (found by searching Anaconda Prompt in your search bar), using conda\n",
        "\n",
        "\n",
        "```\n",
        "conda install <name of the module>\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDp7l4nu1V0M"
      },
      "source": [
        "## What is Tensorflow and how do I download it?\n",
        "\n",
        "[Tensorflow](https://www.tensorflow.org/) is an open-source macine learning platform. It can be used to train and deploy machine learning applications.\n",
        "\n",
        "For projects such as ours, we recommend using tensorflow-gpu. We recommend to install tenosrflow-gpu first, and then download the CUDA and the cuDNN libraries (other packages which work with your GPU).\n",
        "[This](https://towardsdatascience.com/installing-tensorflow-with-cuda-cudnn-and-gpu-support-on-windows-10-60693e46e781) is an incredible guide on how to install CUDA/cuDNN or the official NVIDIA tutorial for [Windows](https://docs.nvidia.com/cuda/cuda-installation-guide-microsoft-windows/index.html)- if you need a hand, feel free to open up an issue within this repository.\n",
        "\n",
        "\n",
        "```\n",
        "2021-01-06 17:05:11.751597: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0';\n",
        "dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/Qt/5.14.1/lib\n",
        "2021-01-06 17:05:11.751625: I tensorflow/stream_executor/cuda/cudart_stub.cc:29]\n",
        "Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
        "```\n",
        "You may need to add the path to the environment file, where you tell Python where your CUDA has been downloaded to on your computer (*PS: if you use Windows do not forget to restart the PC after CUDA installation because YOUR system environment variables are updated*.\n",
        "\n",
        "If CUDA isn’t properly available to your computer you may also see thIs traceback\n",
        "```\n",
        "Skipping registering GPU devices...\n",
        "```\n",
        "For Linux/Ubuntu users, please this [thread](https://github.com/tensorflow/tensorflow/issues/45930) on issues others have faced.\n",
        "\n",
        "Sometimes going down this route means that certain libraries are missing. In my case, I had the cudart64_101.dll  library missing - you can download it [here](https://www.dll-files.com/cudart64_101.dll.html)\n",
        "\n",
        "Another solution is to install cudatoolkit\n",
        "\n",
        "```\n",
        "conda install cudatoolkit\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h07OZwFT3rPq"
      },
      "source": [
        "## Once you have your GPU installed\n",
        "\n",
        "If you are running your code on a laptop equipped with Tesla GPU’s and you would like to run locally, then you can run the code on your laptop with the tensorflow-gpu version.\n",
        "\n",
        "To check that the GPU on your laptop has successfully connected to the GPU, you can type (*Note this is for when you are using Tensorflow version 2, and above, which you should be!*):\n",
        "\n",
        "If you have a gpu and can use it, you will see the result\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))\n",
        "tf.config.list_physical_devices('GPU')\n",
        "```\n",
        "Here are some other ways.\n",
        "* This code tells you tells if the gpu is available\n",
        "```\n",
        "tf.test.is_gpu_available\n",
        "```\n",
        "This tells you the the name of the gpu device\n",
        "\n",
        "```\n",
        "tf.test.gpu_device_name\n",
        "```\n",
        "\n",
        "If none of these commands work for you, please check [here](https://stackoverflow.com/questions/38009682/how-to-tell-if-tensorflow-is-using-gpu-acceleration-from-inside-python-shell) as well\n",
        "\n",
        "### Debugging \n",
        "If your machine tells you that no GPU is available, this may be for several reasons:\n",
        "* Your default drive memory is full - check your storage and see if you can clear any space\n",
        "* You have a GPU but is not being used; this could be due to the fact that you have not loaded tensorflow-gpu properly, depending on whether you have the CPU version installed as well, to see which version you are using you can either type\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "print(tf.version.VERSION)\n",
        "```\n",
        "OR\n",
        "```\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "```\n",
        "Tensorflow only uses 1 GPU by default, though you can set it to use more than 1…\n",
        "\n",
        "\n",
        "```\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" \n",
        "```\n",
        "GPUs are typically indexed at 0,1,2, So the above code would tell my Tensorflow to use my second GPU. Depending on the resource allocation on your computer, if your default storage us full, it may be that your default GPU easily runs out of memory, if so, check this [link](https://stackoverflow.com/questions/57483567/tensorflow-device-cuda0-not-supported-by-xla-service-while-setting-up-xla-gpu) out\n",
        "\n",
        "When you have successfully connected to your GPU, your output might look something like this: \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "now as GPU, 2021-01-14 12:21:46.446661: tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] \n",
        "Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 1342 MB memory) -> physical GPU (device: 0, name: GeForce MX150, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
        "```\n",
        "Or…\n",
        "```\n",
        "name: \"/device:GPU:0\" device_type: \"GPU\" memory_limit: 10711446324 locality { bus_id: 1 links { }} incarnation: 17935632445266485019 physical_device_desc: \"device: 0, name: GeForce RTX 2080 Ti, pci bus id: 0000:01:00.0, compute capability: 7.5\"] \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXpQ4gL99Fyd"
      },
      "source": [
        "Depending on when you, the reader, see this notebook, it might be advisable to follow these steps to use the latest version of TensorFlow. Further, tensorflow 2.5 has now been published, as well as CUDA 11.3, so these dependencies may change. I will attempt to updated this repository in autumn 2021, to reflect any changes in workflow as a result of these updates.\n",
        "* If using tensorflow 2.5 RC0 version, you can follow these steps\n",
        "1. Install the latest release candidate via \n",
        "```\n",
        "pip install tensorflow-gpu==2.5.0rc0\n",
        "```\n",
        "2. Install CUDA 11.1 with \n",
        "```\n",
        "conda install cudatoolkit=11.1 -c conda-forge\n",
        "```\n",
        "3. Download the missing cuDNN 8.1.0 and placed the .dll files into your environment's Library>bin folder as described [here](https://medium.com/analytics-vidhya/install-tensorflow-gpu-2-4-0-with-cuda-11-0-and-cudnn-8-using-anaconda-8c6472c9653f)\n",
        "\n",
        "If you don't want to install tensorflow-gpu and its dependencies locally, you can see a workaround in the next notebook...\n"
      ]
    }
  ]
}