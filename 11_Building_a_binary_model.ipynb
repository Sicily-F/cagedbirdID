{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "11. Building a binary model.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMpuvPo6aRFmr5AIk2xsajd",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Sicily-F/cagedbirdID/blob/main/11_Building_a_binary_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5oIxqZBS0V8"
      },
      "source": [
        "# 11. Building a binary model\n",
        "\n",
        "Heavily occluded images are typically more difficult to classify than unobstructed. It remains to be seen if occlusion causes a significant drop in model performance. To investigate if this is the case for birds, we built a binary classifier to distinguish between 'caged' and 'uncaged' images in our dataset. 'Caged' photos have cage bars obscuring the bird in the foreground, and 'uncaged photos' do not have bars obstructing the view of the bird in the foreground. The model architecture selected for this binary model was VGG-16, to separate photos into caged and uncaged.  \n",
        "\n",
        "We trained this model for 100 epochs, with a batch size of 16, the Adam optimiser, and patience of 10 epochs. Using the pandas package (McKinney, 2020), the predictions from our model were rounded to either 0 (caged) or 1 (uncaged), then exported as a .csv file, which was then used to sort the photos into caged and uncaged datasets. In total, 1,871 images were detected as uncaged of the original images in the TOT_SP_37 dataset (31.38%, 5,963 images)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8rNFVjKllOA"
      },
      "source": [
        "# This code was inspired from: https://www.kaggle.com/raulcsimpetru/vgg16-binary-classification\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QApDH7iSnRX9"
      },
      "source": [
        "TRAIN_DIR = 'F:/newforegroundanalysis/train' \n",
        "VAL_DIR = 'F:/newforegroundanalysis/val'\n",
        "\n",
        "# A new test directory of all the photos, this was a folder of all the raw ground-truth data - then we sorted all these images\n",
        "test_all = 'F:/allspecies_unaugmented_cropped_tobinary'\n",
        "\n",
        "\n",
        "RANDOM_SEED = 1\n",
        "IMG_SIZE = (224, 224) \n",
        "BATCH_SIZE = 16 \n",
        "\n",
        "\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rotation_range=15,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    brightness_range=[0.5, 1.25],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ")\n",
        "\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    preprocessing_function=tf.keras.applications.vgg16.preprocess_input\n",
        ")\n",
        "\n",
        "\n",
        "train_gen = train_datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    color_mode='rgb',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "val_gen = test_datagen.flow_from_directory(\n",
        "    VAL_DIR,\n",
        "    color_mode='rgb',\n",
        "    target_size=IMG_SIZE,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    seed=RANDOM_SEED\n",
        ")\n",
        "\n",
        "test_gen = test_datagen.flow_from_directory(\n",
        "    test_all, #TEST_DIR\n",
        "    target_size=IMG_SIZE, \n",
        "    batch_size= BATCH_SIZE,\n",
        "    class_mode='binary',\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "# This needs to be downloaded beforehand and placed in the working directory\n",
        "vgg16_weight_path = 'F:/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
        "base_model = tf.keras.applications.VGG16(\n",
        "    weights=vgg16_weight_path,\n",
        "    include_top=False,\n",
        "    input_shape=IMG_SIZE + (3,)\n",
        ")\n",
        "\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(base_model)\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.layers[0].trainable = False\n",
        "\n",
        "model.compile(\n",
        "    loss='binary_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.Adam(lr=0.00001), # lr was only 0.1 before\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "model.summary()\n",
        "\n",
        "EPOCHS = 100\n",
        "\n",
        "filepath = \"F:/VGGBINARYNEWDATASET.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# stop training if there is no improvement in model for 15 consecutives epochs.\n",
        "early_stopping_monitor = EarlyStopping(patience=15)\n",
        "callbacks_list = [checkpoint, early_stopping_monitor]\n",
        "\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    steps_per_epoch=train_gen.samples // BATCH_SIZE,\n",
        "    epochs=EPOCHS,\n",
        "    validation_data=val_gen,\n",
        "    validation_steps=val_gen.samples // BATCH_SIZE,\n",
        "    callbacks=[callbacks_list]\n",
        ")\n",
        "\n",
        "# Load the model to either check the test accuracy or keep training\n",
        "model = load_model('F:/VGGBINARYNEWDATASET.h5')\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "opt = Adam(lr=0.0001)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\t\t\t \n",
        "\t\t\t \n",
        "filepath = \"VGGBINARYNEWDATASET2ndtraining.h5\" #\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
        "# stop training if there is no improvement in model for 6 consecutives epochs.\n",
        "early_stopping_monitor = EarlyStopping(patience=6)\n",
        "callbacks_list = [checkpoint, early_stopping_monitor]\n",
        "\n",
        "EPOCHS = 30\n",
        "model_history_2=model.fit(\n",
        "\ttrain_gen,\n",
        "    steps_per_epoch = train_gen.samples // BATCH_SIZE,\n",
        "    validation_data = val_gen, \n",
        "    validation_steps = val_gen.samples // BATCH_SIZE,\n",
        "    epochs = EPOCHS,\n",
        "    shuffle = True,\n",
        "    callbacks=callbacks_list)\n",
        "\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "\n",
        "#print(\"Training Done\")\n",
        "#model.save(\"F:/binarymodel3.h5\")\n",
        "test_loss, test_acc = model.evaluate(test_gen)\n",
        "print('Test accuracy:', test_acc)\n",
        " \n",
        "\n",
        "#Test accuracy: 0. on all the data: Test accuracy: 0.5770551562309265\n",
        "\n",
        "\n",
        "test_gen.reset() #maybe not used \n",
        "pred=model.predict(test_gen,verbose=1,steps=len(test_gen)) #306/BATCH_SIZE\n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (train_gen.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "filenames=test_gen.filenames\n",
        "\n",
        "import pandas as pd                     \n",
        "#also check here for options: https://stackoverflow.com/questions/56695299/how-should-i-use-mode-predict-generator-to-evaluate-model-performance-in-a-confu\n",
        "\n",
        "cl = np.round(pred)\n",
        "\n",
        "filenames=test_gen.filenames\n",
        "\n",
        "results=pd.DataFrame({\"file\":filenames,\"pr\":pred[:,0], \"class\":cl[:,0]})\n",
        "\n",
        "results.to_csv(\"F:/results11.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EL-HXaeA6Afl"
      },
      "source": [
        "model=load_model(\"F:/VGGBINARYNEWDATASET.h5\")\n",
        "\n",
        "test_gen.reset() \n",
        "pred=model.predict(test_gen,verbose=1,steps=len(test_gen)) \n",
        "predicted_class_indices=np.argmax(pred,axis=1)\n",
        "\n",
        "labels = (train_gen.class_indices)\n",
        "labels = dict((v,k) for k,v in labels.items())\n",
        "predictions = [labels[k] for k in predicted_class_indices]\n",
        "filenames=test_gen.filenames\n",
        "\n",
        "cl = np.round(pred)\n",
        "\n",
        "filenames=test_gen.filenames\n",
        "\n",
        "results=pd.DataFrame({\"file\":filenames,\"pr\":pred[:,0], \"class\":cl[:,0]})\n",
        "\n",
        "results.to_csv(\"results22042.csv\",index=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "msdx3pUgnjm-"
      },
      "source": [
        "Originally, the 'results22042.csv' from Tensorflow has a column for the % accuracy. We had to delete that column and rename the class to class_pred \n",
        "becaue the class is a function in Python, I then had to find and \n",
        "replace the allphotos\\from before the filename (so it was the relative not absolute file path), then the sorting code below works, into files of what the classification is (caged or uncaged)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0IIqTuNng4P"
      },
      "source": [
        "SOURCE_ROOT = 'F:/still_convert/new'\n",
        "DEST_ROOT = 'F:/extra_sorted'\n",
        "\n",
        "\n",
        "with open('results22042.csv') as infile:\n",
        "    next(infile)  # Skip the header row\n",
        "    reader = csv.reader(infile)\n",
        "    seen = set()\n",
        "    for file, class_pred in reader:\n",
        "        # Create a new directory if needed\n",
        "        if class_pred not in seen:\n",
        "            os.mkdir(os.path.join(DEST_ROOT, class_pred))\n",
        "            seen.add(class_pred)\n",
        "        src = os.path.join(SOURCE_ROOT, file)\n",
        "        dest = os.path.join(DEST_ROOT, class_pred, file)\n",
        "        try:\n",
        "            os.rename(src, dest)\n",
        "        except WindowsError as e:\n",
        "            print (e)                \n",
        "            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H9CcB5PPnn5y"
      },
      "source": [
        "Once we had the photos sorted we could create our artifical images, which can be viewed in the next code file."
      ]
    }
  ]
}